<div id="content">
  <div id="abs">

    <h1 class="title mathjax">
<span class="descriptor">Title:</span>Online Learning Rate Adaptation with Hypergradient Descent</h1>
    <div class="authors">
<span class="descriptor">Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baydin%2C+A+G">Atilim Gunes Baydin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cornish%2C+R">Robert Cornish</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rubio%2C+D+M">David Martinez Rubio</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidt%2C+M">Mark Schmidt</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wood%2C+F">Frank Wood</a>
</div>
    <div class="dateline">
  
  
  
    
  
  
    
    
  

  (Submitted on 14 Mar 2017 (<a href="https://arxiv.org/abs/1703.04782v1">v1</a>), last revised 26 Feb 2018 (this version, v3))</div>
    <blockquote class="abstract mathjax">
<span class="descriptor">Abstract:</span>  We introduce a general method for improving the convergence rate of
gradient-based optimizers that is easy to implement and works well in practice.
We demonstrate the effectiveness of the method in a range of optimization
problems by applying it to stochastic gradient descent, stochastic gradient
descent with Nesterov momentum, and Adam, showing that it significantly reduces
the need for the manual tuning of the initial learning rate for these commonly
used algorithms. Our method works by dynamically updating the learning rate
during optimization using the gradient with respect to the learning rate of the
update rule itself. Computing this "hypergradient" needs little additional
computation, requires only one extra copy of the original gradient to be stored
in memory, and relies upon nothing more than what is provided by reverse-mode
automatic differentiation.
</blockquote>
    <!--CONTEXT-->
    <div class="metatable">
      <table summary="Additional metadata">
        <tr>
          <td class="tablecell label">Comments:</td>
          <td class="tablecell comments mathjax">11 pages, 4 figures</td>
        </tr>
        <tr>
          <td class="tablecell label">Subjects:</td>
          <td class="tablecell subjects">
            <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)</td>
        </tr>
        <tr>
          <td class="tablecell label">
<abbr title="Mathematical Subject Classification">MSC</abbr> classes:</td>
          <td class="tablecell msc-classes">68T05</td>
        </tr>
        
        <tr>
          <td class="tablecell label">
<abbr title="Association of Computing Machinery Classification">ACM</abbr> classes:</td>
          <td class="tablecell acm-classes">G.1.6; I.2.6</td>
        </tr>
        
        <tr>
          <td class="tablecell label">Journal reference:</td>
          <td class="tablecell jref">In Sixth International Conference on Learning Representations (ICLR), Vancouver, Canada, April 30 -- May 3, 2018. https://openreview.net/forum?id=BkrsAzWAb</td>
        </tr>
        <tr>
          <td class="tablecell label">Cite as:</td>
          <td class="tablecell arxivid"><span class="arxivid"><a href="https://arxiv.org/abs/1703.04782">arXiv:1703.04782</a> [cs.LG]</span></td>
        </tr>
        <tr>
          <td class="tablecell label"> </td>
          <td class="tablecell arxividv">(or <span class="arxivid">
              <a href="https://arxiv.org/abs/1703.04782v3">arXiv:1703.04782v3</a> [cs.LG]</span> for this version)
          </td>
        </tr>
      </table>
    </div>
  </div>
</div>

    
